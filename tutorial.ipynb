{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d158d04e",
   "metadata": {},
   "source": [
    "# DuckDB tutorial\n",
    "\n",
    "Date: November 2025\n",
    "\n",
    "Group: \n",
    "- Charlotte Michon\n",
    "- Duy Vu Dinh\n",
    "- Valérian Wislez\n",
    "\n",
    "This tutorial will introduce DuckDB, a modern column-oriented DBMS. Its target audience is mainly bachelor students in Computer Science or any person having some experience with relational row-store database like Postgres, MariaDB ... that wants to know how to use column-oriented systems.\n",
    "\n",
    "After describing this technology, we will describe how to get started quickly and easily using Python as the interface to DuckDB.\n",
    "\n",
    "Then we will proceed with basic queries and describe the most important aspects of DuckDB's Postgres-like SQL dialect.\n",
    "\n",
    "Next, we will see more advanced queries, suited to OLAP workload.\n",
    "\n",
    "Finally we will compare it with SQLite, a popular row-store relational DBMS, to highlight the advantages and drawbacks of column-oriented systems.\n",
    "\n",
    "\n",
    "## Table of contents\n",
    "\n",
    "* [1. What is DuckDB?](#What-is-DuckDB?)\n",
    "* [2. Why DuckDB?](#Why-DuckDB?)\n",
    "* [3. Prerequisites](#Prerequisites)\n",
    "* [4. Installation](#Installation)\n",
    "* [5. Hello, DuckDB!](#Hello,-DuckDB!)\n",
    "* [6. Dataset](#Dataset)\n",
    "* [6. Basic queries](#Basic-queries)\n",
    "* [7. Comparison to SQLite](#Comparison-to-SQLite)\n",
    "* [8. Advanced functionalities](#advanced-functionalities)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3396bf9",
   "metadata": {},
   "source": [
    "# What is DuckDB?\n",
    "[DuckDB](https://duckdb.org/) is a database management system originally developed by Mark Raasveldt and Hannes Mühleisen at the Centrum Wiskunde & Informatica (CWI) in the Netherlands and was first released in 2019. It enjoys the following properties. It is:\n",
    "- fast\n",
    "- portable\n",
    "- open-source\n",
    "- in-process\n",
    "- analytical\n",
    "- column-oriented \n",
    "- relational\n",
    "\n",
    "As of November 2025, it's latest stable release is 1.4.1. It is written in C++ and released under the MIT license. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c78702",
   "metadata": {},
   "source": [
    "# Why DuckDB?\n",
    "\n",
    "We will now motivate why using DuckDB is a great choice for modern OLAP data workloads.\n",
    "\n",
    "## Workloads\n",
    "\n",
    "Unlike traditional transactional database systems like MySQL or PostgreSQL, that are optimized for [Online Transaction Processing](https://en.wikipedia.org/wiki/Online_transaction_processing) (OLTP) workloads involving many small reads and writes, DuckDB targets [Online Analytical Processing](https://en.wikipedia.org/wiki/Online_analytical_processing) (OLAP) workloads that require large scans, aggregations, and joins over big datasets. It uses a column-oriented engine with vectorized execution to process millions of rows at high speed, often outperforming both traditional databases and tools like pandas for analytical tasks. It is thus well suited to data science, machine learning, scientific computing, economy, ... Any field requiring many resources to be processed in read-only.\n",
    "\n",
    "\n",
    "## DuckDB's strengths\n",
    "\n",
    "DuckDB stores data in columnar format (instead of row-by-row). This allows it to read only the columns that are needed for a query, which makes it optimal for OLAP analyses.\n",
    "DuckDB processes data in optimized batches (vectors), instead of row-by-row, which improves its speed for large datasets.\n",
    "\n",
    "DuckDB runs inside the application that is using it. There is no database server, no connection to the DBMS, which makes it really easy to use and deploy.\n",
    "\n",
    "DuckDB stands out as an entry-level OLAP tool due to its minimalism and accessibility, making it easier to adopt than distributed systems like [ClickHouse](https://clickhouse.com/), [Druid](https://druid.apache.org/), or [Apache Pinot](https://pinot.apache.org/).\n",
    "\n",
    "It offers good performance and low latencies thanks to its in-process architecture (no network overhead).\n",
    "\n",
    "IT can directly work with files and many other [formats](https://duckdb.org/docs/stable/data/data_sources), such as CSV, parquet, JSON, ... or other  \n",
    "\n",
    "It also supports [extensions](https://duckdb.org/docs/stable/extensions/overview) to enhance its functionalities (e.g. adding support for other file formats, introducing new types, adding domain-specific functionalities).\n",
    "\n",
    "## DuckDB's limitations\n",
    "\n",
    "As it is column-oriented, it is less suited to OLTP workloads.\n",
    "\n",
    "It is not scalable to multiple machines, there's no distributed querying.\n",
    "\n",
    "It has limited support for concurrency\n",
    "\n",
    "Drawback : not distributed, only one node. \n",
    "Advantage : simple, efficient. DuckDB supports a [variety of languages](https://duckdb.org/docs/stable/clients/overview) for interacting with it. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffefc5a4",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "There are some prerequisites for following along this tutorial. Fortunately, it is quite simple to set up.\n",
    "- A recent version of python (3.9+). We would recommend a more recent version, as 3.9 is not supported anymore, yet 3.9 is the minimum version supported by DuckDB. The tutorial has been tested for versions 3.13.7. \n",
    "- Basic SQL knowledge and familiarity with classical row-store DMBSes like MySQL, MariaDB, Postgres, etc.\n",
    "- Familiarity with Python, python virtual environments, and Jupyter Notebooks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac63da6",
   "metadata": {},
   "source": [
    "# Installation\n",
    "\n",
    "DuckDB is available as a module managed by pip, which will be easier to interface with in this notebook, as we only need Python. SQlite is also part of python itself so there is no need to install it.\n",
    "\n",
    "The tutorial has been tested for Python version 3.13.7\n",
    "\n",
    "First, create a Python virtual environment. The following shell command will create a virtual environment in the current directory named 'duckdb':\n",
    "\n",
    "``\n",
    "python -m venv duckdb\n",
    "``\n",
    "\n",
    "We can activate the environment using either on UNIX-like systems:\n",
    "\n",
    "``\n",
    "source duckdb/bin/activate\n",
    "``\n",
    "\n",
    "or on Microsoft Windows:\n",
    "\n",
    "``\n",
    ".\\duckdb\\Scripts\\activate\n",
    "``\n",
    "\n",
    "N.B.: On Windows, this might require to [change the scripts execution policy](https://learn.microsoft.com/en-us/powershell/module/microsoft.powershell.security/set-executionpolicy?view=powershell-7.5) on the host machine. In powershell, one can change it using the following cmdlet. This will allow the system to run scripts for the current process (i.e. terminal session).\n",
    "\n",
    "``\n",
    "Set-ExecutionPolicy -ExecutionPolicy AllSigned -Scope Process\n",
    "``\n",
    "\n",
    "Once the virtual environment is activated, we can start downloading the required libraries.\n",
    "\n",
    "``\n",
    "pip install -r requirements.txt\n",
    "``\n",
    "\n",
    "We are now ready to go.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb27d6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If this cell executes correctly, you have all the dependencies needed for this tutorial.\n",
    "\n",
    "import time\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import sqlite3  # Directly present in python, no need to pip install it\n",
    "import kagglehub\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b69a18",
   "metadata": {},
   "source": [
    "# Hello, DuckDB!\n",
    "We will simply test our DuckDB installation by printing a traditional Hello World. This basic script will create a `.db` file which is able to persist data even after the connexion is closed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2572a020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a simple test to see if duckdb works.\n",
    "# DuckDB allows to perform queries in process only, no file will be created.\n",
    "test_con = duckdb.connect(':memory:')\n",
    "\n",
    "query = \"CREATE TABLE IF NOT EXISTS hello AS SELECT 'Hello, world!'\"\n",
    "\n",
    "test_con.execute(query)\n",
    "\n",
    "fetch = \"SELECT * FROM hello\"\n",
    "\n",
    "result = test_con.execute(fetch).fetchall()\n",
    "\n",
    "print(result)\n",
    "\n",
    "test_con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e837e0bc",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "We will now fetch a dataset that best suits our needs. \n",
    "There are multiple ways to get a dataset. We will use an easy, online-fetch of a parquet file.\n",
    "DuckDB is able to handle a [variety](https://duckdb.org/docs/stable/data/overview) of filetypes, including CSV, JSON, parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bc02e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = kagglehub.dataset_download(\"kartik2112/fraud-detection\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "df = pd.read_csv(path + \"/fraudTrain.csv\")\n",
    "df = df.drop(columns=[\"Unnamed: 0\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de52a248",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad637a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf4cc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb9a500",
   "metadata": {},
   "source": [
    "# Basic queries\n",
    "Show that simple queries are just like in traditional sql. We will create a DuckDB instance and show a few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ea0dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = duckdb.connect()\n",
    "con.register(\"fraud\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d87039",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM fraud\n",
    "    LIMIT 5\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0753c051",
   "metadata": {},
   "source": [
    "Let's count how many transactions there are :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fd50e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"\"\"\n",
    "    SELECT COUNT(*) AS n_transactions\n",
    "    FROM fraud\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a015c6cd",
   "metadata": {},
   "source": [
    "Total and average transaction amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421c4831",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"\"\"\n",
    "    SELECT \n",
    "        SUM(amt)  AS total_amount,\n",
    "        AVG(amt)  AS avg_amount\n",
    "    FROM fraud\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4697ebd",
   "metadata": {},
   "source": [
    "Distinct customers and cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e448e86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"\"\"\n",
    "    SELECT\n",
    "        COUNT(DISTINCT cc_num) AS n_customers,\n",
    "        COUNT(DISTINCT city)   AS n_cities\n",
    "    FROM fraud\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ec20fc",
   "metadata": {},
   "source": [
    "Fraud vs non-fraud counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9568a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"\"\"\n",
    "    SELECT \n",
    "        is_fraud,\n",
    "        COUNT(*) AS n\n",
    "    FROM fraud\n",
    "    GROUP BY is_fraud\n",
    "    ORDER BY is_fraud\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2536f003",
   "metadata": {},
   "source": [
    "# Comparison to SQLite\n",
    "Now that we know how to use DuckDB, we will illustrate its advantages and drawbacks against SQLite, a popular row-store DBMS, by performing some more advanced queries.\n",
    "\n",
    "## What is SQLite?\n",
    "\n",
    "SQLite is a **serverless, open-source, row-store, relational** database engine that stores an entire database (including tables, indexes, and data) as a single cross-platform file. As for DuckDB, SQLite runs directly **in-process**, requiring zero configuration and no separate server.\n",
    "It supports SQL standards, ACID transactions, and can handle databases up to several terabytes in size. \n",
    "Because of its **simplicity, reliability, and tiny footprint**, SQLite is **the most widely deployed database in the world**. It is embedded in billions of applications, smartphones, browsers, desktop applications, IoT devices, etc.\n",
    "\n",
    "## Speed comparison with SQLite\n",
    "We will now perform several operations on both database systems to highlight the key performance differences between row stores and column stores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1281ad0",
   "metadata": {},
   "source": [
    "Let's first connect to a local database file with SQLite:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b3580d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlite_con = sqlite3.connect(\"fraud.sqlite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eba2758",
   "metadata": {},
   "source": [
    "Let's now transfer the dataframe to the database file. This operation is quite heavy and might take about 15 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f48b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df.to_sql(\"fraud\", sqlite_con, if_exists=\"replace\", index=False)\n",
    "\n",
    "con.unregister(\"fraud\")\n",
    "con.register(\"fraud\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4c76fb",
   "metadata": {},
   "source": [
    "We will query the total amount by category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace8d49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = \"\"\"\n",
    "    SELECT\n",
    "        category,\n",
    "        COUNT(*)      AS n_transactions,\n",
    "        SUM(amt)      AS total_amount,\n",
    "        AVG(amt)      AS avg_amount\n",
    "    FROM fraud\n",
    "    GROUP BY category\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb965be3",
   "metadata": {},
   "source": [
    "Let's measure the time taken by DuckDB to execute the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655b102a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "result_duck =  con.sql(query1).df()\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "display(result_duck)\n",
    "print(f\"DuckDB execution time: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b80f7b",
   "metadata": {},
   "source": [
    "Let's do the same for SQLite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1226ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "result_sqlite = pd.read_sql_query(query1, sqlite_con)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "display(result_sqlite)\n",
    "print(f\"SQLite execution time: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e343f2a",
   "metadata": {},
   "source": [
    "# Conclusion : ADD CONCLUSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbfda64",
   "metadata": {},
   "source": [
    "Let's query the fraud rate by category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab03c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query2 = \"\"\"\n",
    "    SELECT\n",
    "        category,\n",
    "        COUNT(*)                    AS n_transactions,\n",
    "        SUM(is_fraud)               AS n_fraud,\n",
    "        AVG(CAST(is_fraud AS REAL)) AS fraud_rate\n",
    "    FROM fraud\n",
    "    GROUP BY category\n",
    "    ORDER BY fraud_rate DESC\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96925440",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "result_duck = con.sql(query2).df()\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "display(result_duck)\n",
    "print(f\"DuckDB execution time: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9083b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "result_sqlite = pd.read_sql_query(query2, sqlite_con)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "display(result_sqlite)\n",
    "print(f\"SQLite execution time: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8fe637",
   "metadata": {},
   "source": [
    "Time-based aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd43d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "query3 = \"\"\"\n",
    "    SELECT\n",
    "        DATE(trans_date_trans_time) AS day,\n",
    "        COUNT(*)                   AS n_transactions,\n",
    "        SUM(is_fraud)              AS n_fraud,\n",
    "        SUM(amt)                   AS total_amount\n",
    "    FROM fraud\n",
    "    GROUP BY day\n",
    "    ORDER BY day\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d09277",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "result_duck = con.sql(query3).df()\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "display(result_duck)\n",
    "print(f\"DuckDB execution time: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f84320a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "result_sqlite = pd.read_sql_query(query3, sqlite_con)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "display(result_sqlite)\n",
    "print(f\"SQLite execution time: {end - start:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa1caea",
   "metadata": {},
   "source": [
    "Rolling Average Transaction Amount per Card (Window Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2f8780",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_window = \"\"\"\n",
    "    SELECT\n",
    "        cc_num,\n",
    "        trans_date_trans_time,\n",
    "        amt,\n",
    "        AVG(amt) OVER (\n",
    "            PARTITION BY cc_num\n",
    "            ORDER BY trans_date_trans_time\n",
    "            ROWS BETWEEN 5 PRECEDING AND CURRENT ROW\n",
    "        ) AS rolling_avg_amt\n",
    "    FROM fraud\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b797150",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "result_duck = con.sql(query_window).df()\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "display(result_duck)\n",
    "print(f\"DuckDB execution time: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cc6c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "result_sqlite = pd.read_sql_query(query_window, sqlite_con)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "display(result_sqlite)\n",
    "print(f\"SQLite execution time: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c84d9be",
   "metadata": {},
   "source": [
    "# add one last complex query for comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805c8b58",
   "metadata": {},
   "source": [
    "## Advanced functionalities\n",
    "ideas:\n",
    "querying files directly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2309341b",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "[Wikipedia article about DuckDB](https://en.wikipedia.org/wiki/DuckDB)\n",
    "\n",
    "[The official DuckDB website](https://duckdb.org/)\n",
    "\n",
    "[DuckDB Python API](https://duckdb.org/docs/stable/clients/python/overview)\n",
    "\n",
    "[The official SQLite website](https://sqlite.org/)\n",
    "\n",
    "[Wikipedia article about SQLite](https://en.wikipedia.org/wiki/SQLite)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adb (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
